{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "from utils.util import mkdir,seed_all\n",
    "from omegaconf import OmegaConf\n",
    "from cprint import *\n",
    "from datasets.shape_net import ShapeNet\n",
    "import torch\n",
    "from models.Transform2D import Transform2D\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "%load_ext autoreload\n",
    "%load_ext tensorboard\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Expirement Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m{'logs_dir': 'logs', 'is_train': True, 'name': 'trainingV10', 'device': 'cuda:0', 'batch_size': 8, 'n_epochs': 100, 'print_every': 20, 'validate_every': 30, 'save_every': 50, 'save_every_nepochs': 10, 'model': {'lr': 0.0001, 'criterion': 'BCE', 'pos_weight': 1.3, 'encoder': {'patch_size': 13, 'sequence_length': 100, 'embedding_dim': 768, 'patch_padding': 3}, 'transformer_encoder': {'d_model': 768, 'nhead': 12, 'num_layers': 12}, 'transformer_decoder': {'d_model': 768, 'nhead': 12, 'num_layers': 8, 'num_pos_embeddings': 64}}}\u001b[0m\n",
      "\u001b[94m- logs directory found\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m- Creating new directory logs/trainingV10\u001b[0m\n",
      "\u001b[93m- Creating new directory logs/trainingV10/checkpoints\u001b[0m\n",
      "\u001b[93m- Creating new directory logs/trainingV10/tb\u001b[0m\n",
      "\u001b[93m- Creating new directory logs/trainingV10/visuals\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "seed_all(111)\n",
    "today = time.strftime(\"%Y-%m-%d\")\n",
    "config = OmegaConf.load(\"./configs/global_configs.yaml\")\n",
    "cprint.ok(config)\n",
    "description = \"Testing training script\" # Describe Experiment params here\n",
    "logs_dir = config[\"logs_dir\"]\n",
    "mkdir(logs_dir)\n",
    "experiment_dir = f\"{logs_dir}/{config['name']}\"\n",
    "mkdir(experiment_dir)\n",
    "loss_log_title = \"Loss Log\" + today \n",
    "\n",
    "with open(f\"{experiment_dir}/description.txt\", \"w\") as file1:\n",
    "    file1.write(description)\n",
    "    \n",
    "with open(f\"{experiment_dir}/configs.txt\", \"w\") as file1:\n",
    "    file1.write(str(config))\n",
    "\n",
    "with open(f\"{experiment_dir}/loss_log.txt\", \"w\") as file1:\n",
    "    file1.write(loss_log_title)\n",
    "    file1.write(\"\\n\")\n",
    "\n",
    "\n",
    "mkdir(f\"{experiment_dir}/checkpoints\")\n",
    "mkdir(f\"{experiment_dir}/tb\")\n",
    "mkdir(f\"{experiment_dir}/visuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset & Dataloaders\n",
    "This uses a random split for train/validation/test - might need to look into paper if they have a pre-defined split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  64\n"
     ]
    }
   ],
   "source": [
    "dataset = ShapeNet(cat=\"airplane\",is_overfit=True) #Change overfit param here & cat here\n",
    "print('length: ', len(dataset))\n",
    "train_ds, valid_ds, test_ds = torch.utils.data.random_split(\n",
    "    dataset, [56, 8, 0])\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_ds,   # Datasets return data one sample at a time; Dataloaders use them and aggregate samples into batches\n",
    "        batch_size=config['batch_size'],   # The size of batches is defined here\n",
    "        shuffle=True,    # Shuffling the order of samples is useful during training to prevent that the network learns to depend on the order of the input data\n",
    "        num_workers=4,   # Data is usually loaded in parallel by num_workers\n",
    "        pin_memory=True,  # This is an implementation detail to speed up data uploading to the GPU\n",
    "        # worker_init_fn=train_dataset.worker_init_fn  TODO: Uncomment this line if you are using shapenet_zip on Google Colab\n",
    "    )\n",
    "\n",
    "validation_dataloader = torch.utils.data.DataLoader(\n",
    "        train_ds,   # Datasets return data one sample at a time; Dataloaders use them and aggregate samples into batches\n",
    "        batch_size=config['batch_size'],   # The size of batches is defined here\n",
    "        shuffle=True,    # Shuffling the order of samples is useful during training to prevent that the network learns to depend on the order of the input data\n",
    "        num_workers=4,   # Data is usually loaded in parallel by num_workers\n",
    "        pin_memory=True,  # This is an implementation detail to speed up data uploading to the GPU\n",
    "        # worker_init_fn=train_dataset.worker_init_fn  TODO: Uncomment this line if you are using shapenet_zip on Google Colab\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mUsing device:\u001b[0m cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transform2D(\n",
       "  (patch_encoder): PatchEncoder(\n",
       "    (pos_embedding): Embedding(100, 768)\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(4, 768, kernel_size=(13, 13), stride=(13, 13))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (net): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (6): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (7): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (8): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (9): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (10): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (11): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (net): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (6): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (7): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pos_embeddings): Embedding(64, 768)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): SimpleDecoder(\n",
       "    (initial_conv): Conv3d(768, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (encoded_conv): Sequential(\n",
       "      (0): ResBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (3): ReLU()\n",
       "          (4): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (3): ReLU()\n",
       "          (4): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_transpose): Sequential(\n",
       "      (0): ConvTranspose3d(64, 64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): ConvTranspose3d(64, 64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): ConvTranspose3d(64, 64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (conv_transpose4): ConvTranspose3d(64, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Transform2D()\n",
    "# Declare device\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available() and config['device'].startswith('cuda'):\n",
    "    device = torch.device(config['device'])\n",
    "    cprint.ok('Using device:', config['device'])\n",
    "else:\n",
    "    cprint.warn('Using CPU')\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Checklist:\n",
    "- Add tensorboard and make sure it logs to the `${experiment_dir}/tb` folder\n",
    "- Visualize some reconstructions on validation set and make sure it logs to the `${expirement_dir}/visuals` folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c1b849758243cd80b0c97e123acd68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b093d16dc2a149aebac4d79df57cab5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-0.ckpt created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946de39c8a9443528ceac92127c76b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976db0ac525643b3939647c91b274fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1852, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[002/00005] train_loss: 0.204637\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aed2c5cb02a4a3eae091c594ccdc77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef776a1a8b041a38cbddd682c4588d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mRunning Validation\u001b[0m\n",
      "logs/trainingV10/checkpoints/epoch-best.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[004/00001] val_loss: 0.153316 | best_loss_val: 0.153316\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0dab3d4e2e042fcbcf7340a1a69e26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "self._shutdown_workers()\n",
      "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      "Traceback (most recent call last):\n",
      ":   File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "can only test a child process      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "\n",
      "if w.is_alive():    \n",
      "self._shutdown_workers()  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n",
      "\n",
      "AssertionError  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      ":     can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1197, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[005/00004] train_loss: 0.137990\u001b[0m\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in:   File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "    Traceback (most recent call last):\n",
      "self._shutdown_workers()  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    Exception ignored in: self._shutdown_workers()"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ad3ab70b804662a05346b63709e2ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "if w.is_alive():\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "    \n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "self._shutdown_workers()AssertionError\n",
      "    :   File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "\n",
      "if w.is_alive():AssertionError\n",
      ":   File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "can only test a child process    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6076a527763c4ae2a844bba08c87dcf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-latest.ckpt created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90e59f5c75141e593cf3269b1979da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0767, device='cuda:0')\n",
      "\u001b[94mRunning Validation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[008/00003] train_loss: 0.088448\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-best.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[008/00003] val_loss: 0.088840 | best_loss_val: 0.088840\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d5ff528f684eaeb1ae34f169eff80f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647b084c9ff24c6f892df1c4c90849d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-10.ckpt created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52c82aaa3964f94bfd313154cd98d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0771, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[011/00002] train_loss: 0.073478\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abea858090af4c13a82d1f257f214206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mRunning Validation\u001b[0m\n",
      "logs/trainingV10/checkpoints/epoch-best.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[012/00005] val_loss: 0.070532 | best_loss_val: 0.070532\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e1f5991d734fa99272afdd6d05656b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4fbd46cbf040ae96397c31d05ce55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0618, device='cuda:0')\n",
      "logs/trainingV10/checkpoints/epoch-latest.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[014/00001] train_loss: 0.067703\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c45e389a1744194b17c81ddd8e2d9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>Exception ignored in: \n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "    <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "        self._shutdown_workers()if w.is_alive():\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "            AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'self._shutdown_workers()\n",
      "\n",
      "self._shutdown_workers()  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "AssertionError: : \n",
      "can only test a child process    can only test a child process  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "\n",
      "if w.is_alive():\n",
      "\n",
      "    if w.is_alive():  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError\n",
      ": AssertionErrorcan only test a child process: \n",
      "can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>Exception ignored in: \n",
      "Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>Exception ignored in:   File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a1d27fc7964230a24bd0c8710e5cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>Traceback (most recent call last):\n",
      "\n",
      "    Exception ignored in:   File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "Traceback (most recent call last):\n",
      "self._shutdown_workers()  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>self._shutdown_workers()  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    \n",
      "\n",
      "self._shutdown_workers()  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    Traceback (most recent call last):\n",
      "\n",
      "if w.is_alive():  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    \n",
      "          File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "if w.is_alive():if w.is_alive():\n",
      "    \n",
      "self._shutdown_workers()  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "    \n",
      "      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "\n",
      ": if w.is_alive():AssertionErrorAssertionError: \n",
      "can only test a child process: can only test a child process\n",
      "can only test a child process  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8341ceb966b453385e5b9e62d67335d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710><function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "        self._shutdown_workers()\n",
      "self._shutdown_workers()  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "\n",
      "      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "if w.is_alive():    \n",
      "if w.is_alive():  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "    AssertionError: assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process\n",
      "\n",
      "AssertionError: can only test a child processException ignored in: Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710><function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>Traceback (most recent call last):\n",
      "\n",
      "Exception ignored in: \n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "self._shutdown_workers()    \n",
      "\n",
      "self._shutdown_workers()Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "        self._shutdown_workers()if w.is_alive():    self._shutdown_workers()\n",
      "\n",
      "if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'    if w.is_alive():\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionErrorif w.is_alive()::   File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "\n",
      "can only test a child process    AssertionError  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      ": \n",
      "    AssertionErrorcan only test a child processException ignored in: : \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process\n",
      "\n",
      "\n",
      "AssertionErrorTraceback (most recent call last):\n",
      "Exception ignored in: : <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "can only test a child processException ignored in: \n",
      "\n",
      "    Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "self._shutdown_workers()\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>    Traceback (most recent call last):\n",
      "\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "self._shutdown_workers()          File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "\n",
      "self._shutdown_workers()if w.is_alive():\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "self._shutdown_workers()\n",
      "      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    if w.is_alive():\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    \n",
      "\n",
      "      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "if w.is_alive():AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "\n",
      ":   File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process    \n",
      "\n",
      "AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError\n",
      ": Exception ignored in: : can only test a child processAssertionErrorcan only test a child process\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>: can only test a child process\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>    \n",
      "\n",
      "self._shutdown_workers()Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "Traceback (most recent call last):\n",
      "      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "        self._shutdown_workers()self._shutdown_workers()    \n",
      "if w.is_alive():\n",
      "self._shutdown_workers()  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():    if w.is_alive():\n",
      "      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    \n",
      "\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "    \n",
      "AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'AssertionErrorAssertionError\n",
      ": : : can only test a child processcan only test a child processcan only test a child process\n",
      "AssertionError\n",
      "\n",
      ": can only test a child processException ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in:   File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>    \n",
      "self._shutdown_workers()Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    self._shutdown_workers()    \n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "if w.is_alive():    if w.is_alive():\n",
      "\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "AssertionError: AssertionErrorcan only test a child process: \n",
      "can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0547, device='cuda:0')\n",
      "\u001b[94mRunning Validation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[017/00000] train_loss: 0.054744\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-best.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[017/00000] val_loss: 0.064642 | best_loss_val: 0.064642\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232ca8e7455c462790b28f37bb53413f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfaeb42443044d88b550d5ef64491d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0511, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[019/00006] train_loss: 0.064760\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ea6868735e4056a3e2ea099c2faee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-20.ckpt created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d257c27c8149cb8fe8060766b037b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-latest.ckpt created\n",
      "\u001b[94mRunning Validation\u001b[0m\n",
      "logs/trainingV10/checkpoints/epoch-best.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[021/00002] val_loss: 0.063056 | best_loss_val: 0.063056\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfce1fd6832a43f1ac355c4dffebc576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0531, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[022/00005] train_loss: 0.064422\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe25918f8d41424d93f6071fdd88e6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bae30756eef411b926abaaa67f77226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb66b3c4027243279e869369f986cbbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0508, device='cuda:0')\n",
      "\u001b[94mRunning Validation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[025/00004] train_loss: 0.058797\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-best.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[025/00004] val_loss: 0.062435 | best_loss_val: 0.062435\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4791898c7c2a4510a7e103c46b16fba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78f8b89d7d24825b8cc2db584d2611f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910e3676355f4947940675397d877ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0513, device='cuda:0')\n",
      "logs/trainingV10/checkpoints/epoch-latest.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[028/00003] train_loss: 0.064002\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680632c704eb4ffea4c77b19b80ffa51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mRunning Validation\u001b[0m\n",
      "logs/trainingV10/checkpoints/epoch-best.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[029/00006] val_loss: 0.061807 | best_loss_val: 0.061807\u001b[0m\n",
      "Exception ignored in: Exception ignored in: "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2166922d3d452e98bd9ccd45c235bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710><function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in:   File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "    <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "self._shutdown_workers()          File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "if w.is_alive():\n",
      "self._shutdown_workers()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    \n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "if w.is_alive():        \n",
      "if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "if w.is_alive():  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "AssertionError  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      ": \n",
      "    can only test a child process  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError\n",
      "AssertionError: : can only test a child processAssertionErrorcan only test a child process: \n",
      "\n",
      "can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-30.ckpt created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5be310d760d4b7d81fdd3cea976ddd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0696, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[031/00002] train_loss: 0.063612\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6dfa73a955a4536827216772e88c455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96db59b8bff046c39f4623d36b5df475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1911bb110542398ac1e45140009d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0951, device='cuda:0')\n",
      "\u001b[94mRunning Validation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[034/00001] train_loss: 0.076628\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-best.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[034/00001] val_loss: 0.061659 | best_loss_val: 0.061659\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1bc2812d3743a6bbf6e18055772813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-latest.ckpt created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720981e324bb4c46be18797e8dc7fd52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c26fe8ff67e45e89961ac2da1d16752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0887, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[037/00000] train_loss: 0.088695\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1c708abf7747debb50b8675c742ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mRunning Validation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[038/00003] val_loss: 0.062476 | best_loss_val: 0.061659\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a12b99df7854d1187a22e9bf3959cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0552, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[039/00006] train_loss: 0.062862\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5165d198429543c0bd6e2e29f4949766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-40.ckpt created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bc3b2e0c2c455abec0e0e57ce8f90d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5cc61d48eb41dbb87b64ed8cf15ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0687, device='cuda:0')\n",
      "logs/trainingV10/checkpoints/epoch-latest.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[042/00005] train_loss: 0.062017\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mRunning Validation\u001b[0m\n",
      "logs/trainingV10/checkpoints/epoch-best.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[042/00005] val_loss: 0.061374 | best_loss_val: 0.061374\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a00f7e7732b4da894ca40eac1265217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d76431fc3344ae78d7836c698a07062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f0dfdffb4747898d29826a17cb80f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0497, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[045/00004] train_loss: 0.058841\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590f578daba7405da28b7a317af5ffd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a391eda145c94350a844670a079ecf39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mRunning Validation\u001b[0m\n",
      "logs/trainingV10/checkpoints/epoch-best.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[047/00000] val_loss: 0.060949 | best_loss_val: 0.060949\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3202cb522bc4413792ab62e4d84a983a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0808, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[048/00003] train_loss: 0.062520\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f23bd08adef428e84b1e413f4adf8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-latest.ckpt created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a89dff87454bc1ac6fcbac3401140d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-50.ckpt created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835264c34f6f458eb32c5dcee5148282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0642, device='cuda:0')\n",
      "\u001b[94mRunning Validation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[051/00002] train_loss: 0.064837\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-best.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[051/00002] val_loss: 0.060568 | best_loss_val: 0.060568\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c73b36f449d74e9fb108122804f69cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dffc0cebb3a34a49ada7a9204329f658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0af21caaab4edc801c751ed7721bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0719, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[054/00001] train_loss: 0.059203\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db47c07c137946bf91b015fd30a7c9c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mRunning Validation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[055/00004] val_loss: 0.060943 | best_loss_val: 0.060568\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85bd6cab04564895b014bcdb58bc4f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851ab015d7cb4ef08142ef248d94a8e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0764, device='cuda:0')\n",
      "logs/trainingV10/checkpoints/epoch-latest.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[057/00000] train_loss: 0.076381\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8916d7dfcf142fd8332eba73c596058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>Traceback (most recent call last):\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "\n",
      "    Traceback (most recent call last):\n",
      "self._shutdown_workers()Exception ignored in: \n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "if w.is_alive():    \n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "self._shutdown_workers()      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "if w.is_alive():        \n",
      "self._shutdown_workers()  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():AssertionError        \n",
      ": assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "    can only test a child process\n",
      "AssertionError  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "    : assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "AssertionError: can only test a child processcan only test a child process\n",
      "AssertionError\n",
      ": can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>Traceback (most recent call last):\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    \n",
      "self._shutdown_workers()    Traceback (most recent call last):\n",
      "Exception ignored in: \n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd129cb3238342fd906e45869210fd33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "\n",
      "\n",
      "      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    Traceback (most recent call last):\n",
      "self._shutdown_workers()if w.is_alive():  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    \n",
      "\n",
      "if w.is_alive():      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "self._shutdown_workers()\n",
      "      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process':     \n",
      "\n",
      "if w.is_alive():can only test a child processAssertionError  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "\n",
      ":   File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "can only test a child process    \n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "AssertionErrorAssertionError: : can only test a child processcan only test a child process\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0580, device='cuda:0')\n",
      "\u001b[94mRunning Validation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[059/00006] train_loss: 0.061094\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-best.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[059/00006] val_loss: 0.060563 | best_loss_val: 0.060563\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97adf8ad6007450680af004cd8a8469d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-60.ckpt created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be01ce470a3f4a16a10b571388b76e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e8baf43a5f4249a4bb3e897f97ee2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0518, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[062/00005] train_loss: 0.061019\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2eaa7f51cb438e8ccc50e6dca8f212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a424613b4204d29a2e880f0af108887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-latest.ckpt created\n",
      "\u001b[94mRunning Validation\u001b[0m\n",
      "logs/trainingV10/checkpoints/epoch-best.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[064/00001] val_loss: 0.060244 | best_loss_val: 0.060244\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222633f5753649f2bede3c6a4ee5a529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0521, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[065/00004] train_loss: 0.061551\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120a2045800a4d84ba657a082d0877b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dffa645c44d4690a9ef4bf671191001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e865645a999f48b282eb54d3a93c9b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0567, device='cuda:0')\n",
      "\u001b[94mRunning Validation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[068/00003] train_loss: 0.066017\u001b[0m\n",
      "\u001b[93m[068/00003] val_loss: 0.060699 | best_loss_val: 0.060244\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d251d22f45864feb91b6a2bbe42f77a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6578230e381a40edbcf3f546da117dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-70.ckpt created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f33acd3ca542bf90ca8132e14728cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0764, device='cuda:0')\n",
      "logs/trainingV10/checkpoints/epoch-latest.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[071/00002] train_loss: 0.067284\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d43bba5f7d942a0a8546e1e992f429f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mRunning Validation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[072/00005] val_loss: 0.060451 | best_loss_val: 0.060244\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ce8c5c3ee44f79833fe4d77375c24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0657d3d55a4342b8b35cb336ab8f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0697, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[074/00001] train_loss: 0.068390\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f97b64f567048f2b37da6dcf1ad2d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f28cf32815a4213aa693a10e604e18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcbebb1ddc304eb9beacf3354c80f4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0686, device='cuda:0')\n",
      "\u001b[94mRunning Validation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[077/00000] train_loss: 0.068566\u001b[0m\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in:   File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710><function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "Traceback (most recent call last):\n",
      "      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "self._shutdown_workers()Traceback (most recent call last):\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()    \n",
      "self._shutdown_workers()  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "        \n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():if w.is_alive():\n",
      "\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: if w.is_alive():\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "can only test a child processAssertionError    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'self._shutdown_workers(): \n",
      "\n",
      "can only test a child process  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "\n",
      "AssertionError    : if w.is_alive():can only test a child process\n",
      "\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "\u001b[93m[077/00000] val_loss: 0.060358 | best_loss_val: 0.060244\u001b[0m\n",
      "Exception ignored in: Exception ignored in: "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ccf3414b034476984322ad2ae98d277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710><function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    Exception ignored in:         <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>self._shutdown_workers()self._shutdown_workers()\n",
      "self._shutdown_workers()Traceback (most recent call last):\n",
      "\n",
      "\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "                self._shutdown_workers()if w.is_alive():if w.is_alive():if w.is_alive():\n",
      "\n",
      "\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "            assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "    if w.is_alive():\n",
      "AssertionErrorAssertionError\n",
      ": assert self._parent_pid == os.getpid(), 'can only test a child process':   File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "can only test a child process\n",
      "    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child processAssertionError\n",
      "\n",
      ": AssertionErrorException ignored in: : can only test a child processException ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>can only test a child process\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>    \n",
      "self._shutdown_workers()  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "self._shutdown_workers()Exception ignored in:     \n",
      "    <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>self._shutdown_workers()if w.is_alive():  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "\n",
      "    \n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "Traceback (most recent call last):\n",
      "if w.is_alive():\n",
      "    \n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "AssertionError  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "self._shutdown_workers():     \n",
      "AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process\n",
      "\n",
      ":   File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "can only test a child processAssertionError\n",
      "    : if w.is_alive():can only test a child process\n",
      "\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-latest.ckpt created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b04c96dfb794ef296443c48dad78b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0580, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[079/00006] train_loss: 0.060600\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c3cf23cbde48b1866b4c3d719f28f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-80.ckpt created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd558433072465aa677618d22ef2bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mRunning Validation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[081/00002] val_loss: 0.060309 | best_loss_val: 0.060244\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6cf623367c4d28bfc978ea5ae0f7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0683, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[082/00005] train_loss: 0.058888\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf2e34e1e2e42c58a399ca14aabc807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524ffd6f048f43aba77bf978fbd674da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    \n",
      "Traceback (most recent call last):\n",
      "self._shutdown_workers()\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>Exception ignored in: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>        self._shutdown_workers()\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "self._shutdown_workers()    Traceback (most recent call last):\n",
      "    if w.is_alive():  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "\n",
      "\n",
      "    self._shutdown_workers()  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "            assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():if w.is_alive():\n",
      "\n",
      "\n",
      "AssertionErrorif w.is_alive():  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      ":   File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    can only test a child process      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionErrorAssertionError: AssertionError: can only test a child process: \n",
      "can only test a child processcan only test a child process\n",
      "\n",
      "Exception ignored in: Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710><function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710><function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "Traceback (most recent call last):\n",
      "self._shutdown_workers()      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b9429c56d546a58839c80c4f38573a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    self._shutdown_workers()\n",
      "self._shutdown_workers()    \n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "self._shutdown_workers()  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "        if w.is_alive():\n",
      "    if w.is_alive():\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "          File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "if w.is_alive():  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "        \n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "    : \n",
      "can only test a child processAssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError: \n",
      "\n",
      "can only test a child process: AssertionErrorcan only test a child process\n",
      ": \n",
      "can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0643, device='cuda:0')\n",
      "logs/trainingV10/checkpoints/epoch-latest.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[085/00004] train_loss: 0.057837\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mRunning Validation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[085/00004] val_loss: 0.060465 | best_loss_val: 0.060244\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0166853927461593f38ec235425d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc2ff22e77c4a5095d3e965b45de639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76b2db802804ad790c25ebda30bedd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0754, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[088/00003] train_loss: 0.060530\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47fa1a8980b540aba0cd049c2c41b0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mRunning Validation\u001b[0m\n",
      "logs/trainingV10/checkpoints/epoch-best.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[089/00006] val_loss: 0.059965 | best_loss_val: 0.059965\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae0060355da48e08db0af8b69c42def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710><function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():Exception ignored in: \n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710><function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "        self._shutdown_workers()if w.is_alive():\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "Traceback (most recent call last):\n",
      "\n",
      "      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "if w.is_alive():            \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": can only test a child process\n",
      "self._shutdown_workers()\n",
      "AssertionError\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      ": AssertionErrorcan only test a child process    : if w.is_alive():\n",
      "can only test a child process\n",
      "\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-90.ckpt created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f08166223c415d816df381164c1b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0518, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[091/00002] train_loss: 0.060044\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e34e509924445aa3404969eaab969e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/trainingV10/checkpoints/epoch-latest.ckpt created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137888dc05c94bad928b19a823b30527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a662b6d05e9f4e04a1a871630f834b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0481, device='cuda:0')\n",
      "\u001b[94mRunning Validation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[094/00001] train_loss: 0.052552\u001b[0m\n",
      "\u001b[93m[094/00001] val_loss: 0.060175 | best_loss_val: 0.059965\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1863a3bcebe4601a2dfe81292dd6098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ade06e415043359f0bd7a28a9fa062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490687282bab48919e70d2504da7ac01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "self._shutdown_workers()\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>    self._shutdown_workers()\n",
      "\n",
      "if w.is_alive():  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    if w.is_alive():\n",
      "\n",
      "\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "        self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    AssertionError\n",
      ": AssertionError\n",
      ": can only test a child process\n",
      "AssertionErrorcan only test a child processif w.is_alive():: can only test a child process\n",
      "\n",
      "\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0491, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[097/00000] train_loss: 0.049137\u001b[0m\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>Exception ignored in:   File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in:           File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fda9934e710>"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac803a1147a648fd808c0475685143ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "    \n",
      "self._shutdown_workers()  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "Traceback (most recent call last):\n",
      "      File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "\n",
      "    if w.is_alive():  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "if w.is_alive():    \n",
      "\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    self._shutdown_workers()if w.is_alive():\n",
      "        \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/youssef/.cache/pypoetry/virtualenvs/machine_learning_for_3d_geometry_final_pro-8w_t9tN0-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "\n",
      "    AssertionError    if w.is_alive():: AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "can only test a child process\n",
      ": \n",
      "    AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process: \n",
      "can only test a child process\n",
      "AssertionError\n",
      ": can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mRunning Validation\u001b[0m\n",
      "logs/trainingV10/checkpoints/epoch-best.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[098/00003] val_loss: 0.059873 | best_loss_val: 0.059873\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d9576813894db2ba3daa9d22f43a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0655, device='cuda:0')\n",
      "logs/trainingV10/checkpoints/epoch-latest.ckpt created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[099/00006] train_loss: 0.060575\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_loss_running = 0.\n",
    "best_loss_val = np.inf\n",
    "model.train()\n",
    "\n",
    "tb_dir = f\"{experiment_dir}/tb\"\n",
    "writer = SummaryWriter(log_dir=tb_dir)\n",
    "model_checkpoint_path = f\"{experiment_dir}/checkpoints\"\n",
    "loss_log_name = f\"{experiment_dir}/loss_log.txt\"\n",
    "last_loss = 0.\n",
    "last_iou = 0.\n",
    "\n",
    "def train_one_epoch(epoch, writer):\n",
    "     global best_loss_val\n",
    "     global last_loss   \n",
    "     global last_iou\n",
    "     train_loss_running = 0.\n",
    "     train_iou_running = 0.\n",
    "     iteration_count = 0\n",
    "     for batch_idx, batch in tqdm(enumerate(train_dataloader)):\n",
    "         ShapeNet.move_batch_to_device(batch, device)\n",
    "         model.step(batch)\n",
    "         metrics = model.get_metrics()\n",
    "         loss = metrics[\"loss\"]\n",
    "         iou = metrics[\"iou\"]\n",
    "         train_loss_running += loss\n",
    "         train_iou_running += iou\n",
    "         iteration = epoch * len(train_dataloader) + batch_idx   \n",
    "         iteration_count += 1\n",
    "         if iteration % config['print_every'] == (config['print_every'] - 1):\n",
    "            \n",
    "            avg_train_loss = train_loss_running / iteration_count\n",
    "            avg_iou = train_iou_running / iteration_count\n",
    "            message = '(epoch: %d, iters: %d, loss: %.6f, iou: %.6f)' % (epoch, iteration, loss.item(), iou.item())\n",
    "            with open(loss_log_name, \"a\") as log_file:\n",
    "                log_file.write('%s\\n' % message)\n",
    "            print(loss)\n",
    "            cprint.warn(f'[{epoch:03d}/{batch_idx:05d}] train_loss: {avg_train_loss:.6f}')\n",
    "            writer.add_scalar(\"Train/Loss\", avg_train_loss, iteration)\n",
    "            writer.add_scalar(\"Train/iou\", avg_iou, iteration)\n",
    "            last_loss = avg_train_loss\n",
    "            last_iou = avg_iou\n",
    "            train_loss_running = 0.\n",
    "            train_iou_running = 0.\n",
    "            iteration_count = 0\n",
    "         \n",
    "         if iteration % config['save_every'] == (config['save_every'] - 1):\n",
    "            model.save(model_checkpoint_path, \"latest\")\n",
    "            \n",
    "        \n",
    "         if iteration % config['validate_every'] == (config['validate_every'] - 1):\n",
    "            cprint.ok(\"Running Validation\")\n",
    "            model.eval()\n",
    "            loss_val = 0.\n",
    "            iou_val = 0.\n",
    "            index_batch = 0\n",
    "            for batch_val in validation_dataloader:\n",
    "                ShapeNet.move_batch_to_device(batch_val, device)\n",
    "                with torch.no_grad():\n",
    "                    model.inference(batch_val)\n",
    "                    metrics = model.get_metrics()\n",
    "                    loss_val +=  metrics[\"loss\"]\n",
    "                    iou_val += metrics[\"iou\"]\n",
    "                    index_batch += 1\n",
    "            avg_loss_val = loss_val / (index_batch)\n",
    "            avg_iou_val = iou_val / (index_batch)\n",
    "            \n",
    "            if avg_loss_val < best_loss_val:\n",
    "                model.save(model_checkpoint_path, \"best\")\n",
    "                best_loss_val = avg_loss_val\n",
    "            \n",
    "            cprint.warn(f'[{epoch:03d}/{batch_idx:05d}] val_loss: {avg_loss_val:.6f} | best_loss_val: {best_loss_val:.6f}')\n",
    "            writer.add_scalar(\"Validation/Loss\", avg_loss_val, iteration)\n",
    "            #import pdb;pdb.set_trace();\n",
    "            writer.add_scalars('Validation/LossComparison',\n",
    "                    { 'Training' : last_loss, 'Validation' : avg_loss_val },\n",
    "                     iteration)\n",
    "            \n",
    "            writer.add_scalars(\"Validation/iouComparison\",\n",
    "                                 { 'Training' : last_iou, 'Validation' : avg_iou_val},\n",
    "                                     iteration)\n",
    "            \n",
    "            writer.flush()\n",
    "      \n",
    "            return last_loss\n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(config['n_epochs'])):\n",
    "    avg_loss = train_one_epoch(epoch, writer) \n",
    "    if(epoch % config[\"save_every_nepochs\"]==0):\n",
    "        model.save(model_checkpoint_path, epoch)\n",
    "    model.update_lr()\n",
    "    writer.close()\n",
    "            \n",
    "#cprint.ok(f\"Visualizations saved to: {experiment_dir}/visuals\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
