{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "from utils.util import mkdir,seed_all\n",
    "from omegaconf import OmegaConf\n",
    "from cprint import *\n",
    "from datasets.shape_net import ShapeNet\n",
    "import torch\n",
    "from models.Transform2D import Transform2D\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.visualizations import save_voxels\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "%load_ext autoreload\n",
    "%load_ext tensorboard\n",
    "%autoreload 2\n",
    "\n",
    "from evaluation.Evaluation import Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Expirement Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m{'logs_dir': 'logs/final_models/evaluations', 'is_train': True, 'name': 'evaluation_dev', 'device': 'cuda:0', 'batch_size': 8, 'n_epochs': 100, 'append_loss_every': 50, 'print_every': 150, 'validate_every': 4349, 'save_every': 500, 'save_every_nepochs': 10, 'start_epoch': 0, 'start_iteration': 0, 'visualize_every': 1000, 'model': {'lr': 0.0001, 'criterion': 'DICE_BCE', 'pos_weight': 1.8, 'fusion': 'AVG', 'encoder': {'patch_size': 16, 'sequence_length': 196, 'embedding_dim': 768, 'patch_padding': 3}, 'transformer_encoder': {'d_model': 768, 'nhead': 12, 'num_layers': 12}, 'transformer_decoder': {'d_model': 768, 'nhead': 12, 'num_layers': 8, 'num_pos_embeddings': 64}, 'fusion_decoder': {'d_model': 768, 'nhead': 6, 'num_layers': 2}}, 'evaluation': {'ckpt_path': 'logs/final_models/avg_fusion/checkpoints/epoch-latest.ckpt'}}\u001b[0m\n",
      "\u001b[94m- logs/final_models/evaluations directory found\u001b[0m\n",
      "\u001b[94m- logs/final_models/evaluations/evaluation_dev directory found\u001b[0m\n",
      "\u001b[94m- logs/final_models/evaluations/evaluation_dev/checkpoints directory found\u001b[0m\n",
      "\u001b[94m- logs/final_models/evaluations/evaluation_dev/tb directory found\u001b[0m\n",
      "\u001b[94m- logs/final_models/evaluations/evaluation_dev/visuals directory found\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "seed_all(111)\n",
    "today = time.strftime(\"%Y-%m-%d\")\n",
    "config = OmegaConf.load(\"./configs/global_configs.yaml\")\n",
    "cprint.ok(config)\n",
    "description = \"Checking Everything\" # Describe Experiment params here\n",
    "logs_dir = config[\"logs_dir\"]\n",
    "mkdir(logs_dir)\n",
    "experiment_dir = f\"{logs_dir}/{config['name']}\"\n",
    "mkdir(experiment_dir)\n",
    "loss_log_title = \"Loss Log \" + today \n",
    "\n",
    "with open(f\"{experiment_dir}/description.txt\", \"w\") as file1:\n",
    "    file1.write(description)\n",
    "    \n",
    "with open(f\"{experiment_dir}/configs.txt\", \"w\") as file1:\n",
    "    file1.write(str(config))\n",
    "\n",
    "with open(f\"{experiment_dir}/loss_log.txt\", \"w\") as file1:\n",
    "    file1.write(loss_log_title)\n",
    "    file1.write(\"\\n\")\n",
    "\n",
    "\n",
    "mkdir(f\"{experiment_dir}/checkpoints\")\n",
    "mkdir(f\"{experiment_dir}/tb\")\n",
    "mkdir(f\"{experiment_dir}/visuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset & Dataloaders\n",
    "This uses a random split for train/validation/test - might need to look into paper if they have a pre-defined split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  43783\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8220a1caaba44b60a87aec62c3e4b0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m/mnt/hdd/streakfull/3DML/Project/src/evaluation/Evaluation.py\u001b[0m(48)\u001b[0;36mmap_results\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     46 \u001b[0;31m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_top_iou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_iou\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     47 \u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_averages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 48 \u001b[0;31m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     49 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     50 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> self.results_dict[\"overall_average\"]\n",
      "0.6773942622045676\n",
      "ipdb> quit\n"
     ]
    }
   ],
   "source": [
    "dataset = ShapeNet(cat=\"all\",is_overfit=False, nimgs=1) #Change overfit param here & cat here\n",
    "print('length: ', len(dataset))\n",
    "dataset[0]\n",
    "# train_ds, valid_ds, test_ds = torch.utils.data.random_split(\n",
    "#     dataset, [35026, 4379, 4378])\n",
    "\n",
    "train_ds, valid_ds, test_ds = torch.utils.data.random_split(\n",
    "     dataset, [35026, 64, 8693])\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_ds,   # Datasets return data one sample at a time; Dataloaders use them and aggregate samples into batches\n",
    "        batch_size=config['batch_size'],   # The size of batches is defined here\n",
    "        shuffle=True,    # Shuffling the order of samples is useful during training to prevent that the network learns to depend on the order of the input data\n",
    "        num_workers=6,   # Data is usually loaded in parallel by num_workers\n",
    "        pin_memory=True,  # This is an implementation detail to speed up data uploading to the GPU\n",
    "        # worker_init_fn=train_dataset.worker_init_fn  TODO: Uncomment this line if you are using shapenet_zip on Google Colab\n",
    "    )\n",
    "\n",
    "validation_dataloader = torch.utils.data.DataLoader(\n",
    "        valid_ds,   # Datasets return data one sample at a time; Dataloaders use them and aggregate samples into batches\n",
    "        batch_size=config['batch_size'],   # The size of batches is defined here\n",
    "        shuffle=True,    # Shuffling the order of samples is useful during training to prevent that the network learns to depend on the order of the input data\n",
    "        num_workers=6,   # Data is usually loaded in parallel by num_workers\n",
    "        pin_memory=True,  # This is an implementation detail to speed up data uploading to the GPU\n",
    "        # worker_init_fn=train_dataset.worker_init_fn  TODO: Uncomment this line if you are using shapenet_zip on Google Colab\n",
    "    )\n",
    "\n",
    "\n",
    "evaluator = Evaluation(validation_dataloader, model, device, experiment_dir)\n",
    "evaluator.evaluate()\n",
    "evaluator.save_dict()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/deit-base-distilled-patch16-224 were not used when initializing DeiTModel: ['cls_classifier.bias', 'distillation_classifier.bias', 'cls_classifier.weight', 'distillation_classifier.weight']\n",
      "- This IS expected if you are initializing DeiTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DeiTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DeiTModel were not initialized from the model checkpoint at facebook/deit-base-distilled-patch16-224 and are newly initialized: ['deit.pooler.dense.bias', 'deit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mUsing device:\u001b[0m cuda:0\n",
      "Model loaded from logs/final_models/avg_fusion/checkpoints/epoch-latest.ckpt\n"
     ]
    }
   ],
   "source": [
    "model = Transform2D()\n",
    "# Declare device\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available() and config['device'].startswith('cuda'):\n",
    "    device = torch.device(config['device'])\n",
    "    cprint.ok('Using device:', config['device'])\n",
    "else:\n",
    "    cprint.warn('Using CPU')\n",
    "\n",
    "model.to(device)\n",
    "model.load_ckpt(config['evaluation']['ckpt_path'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.mem_get_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Checklist:\n",
    "- Add tensorboard and make sure it logs to the `${experiment_dir}/tb` folder\n",
    "- Visualize some reconstructions on validation set and make sure it logs to the `${expirement_dir}/visuals` folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.visualizations import visualize_png\n",
    "train_loss_running = 0.\n",
    "best_loss_val = np.inf\n",
    "model.train()\n",
    "\n",
    "start_iteration = config[\"start_iteration\"]\n",
    "tb_dir = f\"{experiment_dir}/tb\"\n",
    "writer = SummaryWriter(log_dir=tb_dir)\n",
    "model_checkpoint_path = f\"{experiment_dir}/checkpoints\"\n",
    "loss_log_name = f\"{experiment_dir}/loss_log.txt\"\n",
    "visuals_path =  f\"{experiment_dir}/visuals\"\n",
    "last_loss = 0.\n",
    "last_iou = 0.\n",
    "\n",
    "\n",
    "def train_one_epoch(epoch, writer):\n",
    "     global best_loss_val\n",
    "     global last_loss   \n",
    "     global last_iou\n",
    "     global start_iteration\n",
    "     train_loss_running = 0.\n",
    "     train_iou_running = 0.\n",
    "     iteration_count = 0\n",
    "     for batch_idx, batch in tqdm(enumerate(train_dataloader)):\n",
    "         iteration = epoch * len(train_dataloader) + batch_idx   \n",
    "         if(iteration<= start_iteration):\n",
    "            continue\n",
    "         ShapeNet.move_batch_to_device(batch, device)\n",
    "         model.step(batch)\n",
    "         metrics = model.get_metrics()\n",
    "         loss = metrics[\"loss\"]\n",
    "         iou = metrics[\"iou\"]\n",
    "         train_loss_running += loss\n",
    "         train_iou_running += iou\n",
    "         iteration_count += 1\n",
    "         if iteration % config[\"append_loss_every\"] == (config[\"append_loss_every\"] - 1) or (epoch==0 and iteration==0):\n",
    "            message = '(epoch: %d, iters: %d, loss: %.6f, iou: %.6f)' % (epoch, iteration, loss.item(), iou.item())\n",
    "            with open(loss_log_name, \"a\") as log_file:\n",
    "                log_file.write('%s\\n' % message)\n",
    "            print(loss)\n",
    "         \n",
    "         if iteration % 1000 == 999:\n",
    "            reconstructions = model.x\n",
    "            target = batch[\"voxels\"].squeeze(1)\n",
    "            fig = save_voxels(reconstructions, target, visuals_path, iteration, is_train=True )\n",
    "            writer.add_figure(\"Train/Reconstructions\", fig, global_step=iteration, close=True, walltime=None)\n",
    "                \n",
    "         if iteration % config['print_every'] == (config['print_every'] - 1) or (epoch==0 and iteration==0):\n",
    "            avg_train_loss = train_loss_running / iteration_count\n",
    "            avg_iou = train_iou_running / iteration_count\n",
    "            cprint.warn(f'[{epoch:03d}/{batch_idx:05d}] train_loss: {avg_train_loss:.6f}')\n",
    "            writer.add_scalar(\"Train/Loss\", avg_train_loss, iteration)\n",
    "            writer.add_scalar(\"Train/iou\", avg_iou, iteration)\n",
    "            last_loss = avg_train_loss\n",
    "            last_iou = avg_iou\n",
    "            train_loss_running = 0.\n",
    "            train_iou_running = 0.\n",
    "            iteration_count = 0\n",
    "         \n",
    "         if iteration % config['save_every'] == (config['save_every'] - 1):\n",
    "            model.save(model_checkpoint_path, \"latest\")\n",
    "            \n",
    "        \n",
    "         if iteration % config['validate_every'] == (config['validate_every'] - 1) or (epoch==0 and iteration==0):\n",
    "            cprint.ok(\"Running Validation\")\n",
    "            model.eval()\n",
    "            loss_val = 0.\n",
    "            iou_val = 0.\n",
    "            index_batch = 0\n",
    "            \n",
    "            for batch_idx, batch_val in tqdm(enumerate(validation_dataloader)):\n",
    "                ShapeNet.move_batch_to_device(batch_val, device)\n",
    "                with torch.no_grad():\n",
    "                    model.inference(batch_val)\n",
    "                    metrics = model.get_metrics()\n",
    "                    loss_val +=  metrics[\"loss\"]\n",
    "                    iou_val += metrics[\"iou\"]\n",
    "                    index_batch += 1\n",
    "            avg_loss_val = loss_val / (index_batch)\n",
    "            avg_iou_val = iou_val / (index_batch)\n",
    "            reconstructions = model.x\n",
    "            target = batch_val[\"voxels\"].squeeze(1)\n",
    "            fig = save_voxels(reconstructions, target, visuals_path, iteration, is_train=False )\n",
    "            writer.add_figure(\"Validation/Reconstructions\", fig, global_step=iteration, close=True, walltime=None)\n",
    "            \n",
    "            if avg_loss_val < best_loss_val:\n",
    "                model.save(model_checkpoint_path, \"best\")\n",
    "                best_loss_val = avg_loss_val\n",
    "            \n",
    "            cprint.warn(f'[{epoch:03d}/{batch_idx:05d}] val_loss: {avg_loss_val:.6f} | best_loss_val: {best_loss_val:.6f}')\n",
    "            writer.add_scalar(\"Validation/Loss\", avg_loss_val, iteration)\n",
    "            #import pdb;pdb.set_trace();\n",
    "            writer.add_scalars('Validation/LossComparison',\n",
    "                   { 'Training' : last_loss, 'Validation' : avg_loss_val },\n",
    "                    iteration)\n",
    "            \n",
    "            writer.add_scalars(\"Validation/iouComparison\",\n",
    "                                 { 'Training' : last_iou, 'Validation' : avg_iou_val},\n",
    "                                     iteration)\n",
    "            \n",
    "            writer.flush()\n",
    "      \n",
    "     return last_loss\n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "start_epoch = config[\"start_epoch\"]\n",
    "for epoch in tqdm(range(config['n_epochs'])):\n",
    "    if epoch < start_epoch:\n",
    "        continue\n",
    "    avg_loss = train_one_epoch(epoch, writer) \n",
    "    #if(epoch % config[\"save_every_nepochs\"]==0):\n",
    "    model.save(model_checkpoint_path, epoch)\n",
    "    model.update_lr()\n",
    "    writer.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
